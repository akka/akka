#####################################
# Akka Stream Reference Config File #
#####################################

akka {
  stream {

    # Default materializer settings
    materializer {

      # Initial size of buffers used in stream elements
      initial-input-buffer-size = 4
      # Maximum size of buffers used in stream elements
      max-input-buffer-size = 16

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by ActorMaterializer when creating Actors.
      # When this value is left empty, the default-dispatcher will be used.
      dispatcher = ""

      # Cleanup leaked publishers and subscribers when they are not used within a given
      # deadline
      subscription-timeout {
        # when the subscription timeout is reached one of the following strategies on
        # the "stale" publisher:
        # cancel - cancel it (via `onError` or subscribing to the publisher and
        #          `cancel()`ing the subscription right away
        # warn   - log a warning statement about the stale element (then drop the
        #          reference to it)
        # noop   - do nothing (not recommended)
        mode = cancel

        # time after which a subscriber / publisher is considered stale and eligible
        # for cancelation (see `akka.stream.subscription-timeout.mode`)
        timeout = 5s
      }

      # Enable additional troubleshooting logging at DEBUG log level
      debug-logging = off

      # Maximum number of elements emitted in batch if downstream signals large demand
      output-burst-limit = 1000

      # Enable automatic fusing of all graphs that are run. For short-lived streams
      # this may cause an initial runtime overhead, but most of the time fusing is
      # desirable since it reduces the number of Actors that are created.
      # Deprecated, since Akka 2.5.0, setting does not have any effect.
      auto-fusing = on

      # Those stream elements which have explicit buffers (like mapAsync, mapAsyncUnordered,
      # buffer, flatMapMerge, Source.actorRef, Source.queue, etc.) will preallocate a fixed
      # buffer upon stream materialization if the requested buffer size is less than this
      # configuration parameter. The default is very high because failing early is better
      # than failing under load.
      #
      # Buffers sized larger than this will dynamically grow/shrink and consume more memory
      # per element than the fixed size buffers.
      max-fixed-buffer-size = 1000000000

      # Maximum number of sync messages that actor can process for stream to substream communication.
      # Parameter allows to interrupt synchronous processing to get upsteam/downstream messages.
      # Allows to accelerate message processing that happening withing same actor but keep system responsive.
      sync-processing-limit = 1000

      debug {
        # Enables the fuzzing mode which increases the chance of race conditions
        # by aggressively reordering events and making certain operations more
        # concurrent than usual.
        # This setting is for testing purposes, NEVER enable this in a production
        # environment!
        # To get the best results, try combining this setting with a throughput
        # of 1 on the corresponding dispatchers.
        fuzzing-mode = off
      }

      io.tcp {
        # The outgoing bytes are accumulated in a buffer while waiting for acknoledgment
        # of pending write. This improves throughput for small messages (frames) without
        # sacrificing latency. While waiting for the ack the stage will eagerly pull
        # from upstream until the buffer exceeds this size. That means that the buffer may hold
        # slightly more bytes than this limit (at most one element more). It can be set to 0
        # to disable the usage of the buffer.
        write-buffer-size = 16 KiB
      }
    }

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by ActorMaterializer when creating Actors for IO operations,
    # such as FileSource, FileSink and others.
    blocking-io-dispatcher = "akka.stream.default-blocking-io-dispatcher"

    default-blocking-io-dispatcher {
      type = "Dispatcher"
      executor = "thread-pool-executor"
      throughput = 1

      thread-pool-executor {
        fixed-pool-size = 16
      }
    }

    # configure defaults for SourceRef and SinkRef
    stream-refs {
      # Default initial demand to be sent along with a SinkRef.
      #
      # The receiving side will be prepared to buffer as much as that many elements,
      # and the sending side can assume to safely send as many elements without receiving
      # an demand message before.
      initial-demand = 4

      # Demand is signalled by sending a cumulative demand message ("requesting messages until the n-th sequence number)
      # Using a cumulative demand model allows us to re-deliver the demand message in case of message loss (which should
      # be very rare in any case, yet possible -- mostly under connection break-down and re-establishment).
      #
      # The semantics of handling and updating the demand however are in-line with what Reactive Streams dictates.
      #
      # In normal operation, demand is signalled in response to arriving elements, however if no new elements arrive
      # within `demand-redelivery-interval` a re-delivery of the demand will be triggered, assuming that it may have gotten lost.
      demand-redelivery-interval = 500 ms

      # Idle timeout, after which both sides of the stream-ref will terminate.
      # Notice that demand-redelivery works as a keep-alive, and if a remote Sink keeps receiving the demand re-deliveries,
      # it knows the other side is still alive and will not terminate. The other-side though will eventually decide, by its
      # idle-timeout that "did not get any signal from the remote, over idle-timeout, so will terminate" and that termination
      # would be signalled back to the remote Sink.
      idle-timeout = 5 seconds
    }

  }

  # configure overrides to ssl-configuration here (to be used by akka-streams, and akka-http â€“ i.e. when serving https connections)
  ssl-config {
    protocol = "TLSv1.2"
  }

  actor {

    serializers {
      akka-stream-refs = "akka.stream.remote.serialization.StreamRefSerializer"
    }

    serialization-bindings {
      "akka.stream.remote.scaladsl.SinkRef"    = akka-stream-refs
      "akka.stream.remote.scaladsl.SourceRef"  = akka-stream-refs
      "akka.stream.remote.StreamRefs$Protocol" = akka-stream-refs
    }

    serialization-identifiers {
      "akka.stream.remote.serialization.StreamRefSerializer" = 30
    }
  }
}

# ssl configuration
# folded in from former ssl-config-akka module
ssl-config {
  logger = "com.typesafe.sslconfig.akka.util.AkkaLoggerBridge"
}
